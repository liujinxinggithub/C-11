# 一： 创建和等待多个线程
```c++
void myprint(int inum) {
    cout << "myprint线程开始执行了,线程编号=" << inum << endl;
}

int main() {
    //一：创建和等待多个线程
    vector<thread> mythreads;
    // 创建10个线程，入口统一使用myprint
    // a)10线程还行顺序时乱的，和操作系统对内部线程的运行调度机制有关
    // b)使用迭代器创建多个线程的写法需要记忆（对管理大量线程很方便）
    mythreads.reserve(10);
    for (int i = 0; i < 10; ++i) {
        mythreads.emplace_back(myprint, i);
    }

    for (auto &mythread : mythreads) {
        mythread.join();
    }
    cout << "我爱中国" << endl;
    return 0;
}
```

# 二：数据共享问题分析
##（2.1）只读数据：安全，不需要什么处理手段。直接读就可以；
##（2.2）有读有写：2个线程写，8个线程读。肯定崩溃
最简单的不崩溃处理：读的时候不写，写的时候不读，2个线程不同时写，8个线程不同时读；
##（2.3）共享数据的保护案例代码
网络游戏服务器：两个线程，一个线程收集玩家命令（用一个数字代表），并把命令数据写到一个队列中。
另一个线程，从队列中取出玩家发送来的命令，解析，然后执行玩家需要的动作；
list：频繁的按顺序插入和删除数据时效率高
vector：随机的插入和删除数据时效率高

# 第五节
## （1）互斥量
 互斥量是一个对象，理解成一把锁，多个线程尝试lock()这把锁，只有一个线程锁定成功
 使用时要小心，保护数据不多也不少，少了达不到保护效果。多了，影响效率；
## （2）用法
### （2.1）lock() unlock()
 步骤：先lock()--->操作共享数据--->unlock()
 使用原则：要成对使用，有lock()必然要有unlock()
### （2.2）std::lock_guard: 类模板，忘记unlock(),它替你lock();直接取代Lock()和unlock(),不能在继续使用lock和unlock了
## 三：死锁
### (3.1)死锁至少有两个锁头
### (3.2)解决方案：只要保证两个互斥量上锁顺序一致（不出现交叉），就不会导致死锁；lock_guard也一样！
### (3.3)std::lock()函数模板,但没需要unlock
 能力：可以一次锁定多个锁头（至少两个,一个不行）
 如果一个没锁住，他就在那里等着，等所有都锁住，才往下走。
 要么两个互斥量都锁定，要么都没锁定。如果只锁定了一个，另一个没锁定成功，他会立即解锁锁定了的额，然后专门去锁定没锁定的。
### (3.4)lock_guard的std::adopt_lock
 std::lock_guard<std::mutex> my_guard1(my_mutex1, std::adopt_lock);
 my_guard1的构造会调用lock()函数，加入std::adopt_lock表示构造时已经调用过lock()过了，my_guard1的构造不再需要调用lock()
 析构时照常调用unlock()

# 第六节
## (1)unique_lock取代lock_guard
// unique_lock是一个类模板，在工作中，一般用lock_guard（推荐使用）；
// unique_lock比lock_guard灵活很多；效率上差一点，内存占用多一点
## (2)unique_lock的第二个参数
// std::lock_guard可以带第二个参数
// std::lock_guard<std::mutex> my_guard1(my_mutex1, std::adopt_lock);
### (2.1) std::adopt_lock
//（2.1）std::adopt_lock：表示互斥量已经被lock了（你必须提前lock互斥量，否则报异常）
// std::adopt_lock标记的效果就是“假设调用方线程已经拥有了互斥的所有权（已经lock成功）”；
// 通知lock_guard不需要在构造函数中lock这个互斥量了；
// unique_lock也可以带std::adopt_lock标记，含义相同。就是不希望在unique_lock的构造函数中继续lock
### (2.2) std::try_to_lock
// 我们会尝试用mutex的lock()去锁定这个mutex,但是如果没有成功，我也会立即返回，并不会阻塞在那里；
// 用这个try_to_lock的前提是你不可以先去lock
### (2.3) std::defer_lock
// 前提：不可以自己先lock，否则会报异常
// std::defer_lock：是初始化了一个没有加锁的mutex
## (3)unique_lock的成员函数
//（3.1）lock()，之后离开作用域后，不需要手动unlock
//（3.2）unlock(),可能有一些别的非共享代码要处理。先解锁，处理非共享代码，然后再次lock，去处理共享数据
//（3.3）try_lock()。尝试给互斥量枷锁，成功返回true，失败false
//（3.4）release()。返回它管理的mutex对象指针，并释放所有权；也就是说，这个unique_lock和mutex不在有关系；
// 严格区分unlock()和release()的关系，不要混淆。
// 如果mutex处理加锁状态。你要有责任接管过来，并负责解锁
粒度越细，效率越高！
## (4)unique_lock所有权的传递 (绑定mutex)

# 第七节
## 一：设计模式大概谈
// “设计模式”：代码的一些写法，程序灵活，维护起来方便。

## 二：单例模式（使用频率高）
// 单例：整个项目中，有某个类只能创建一个！
//    MyCAS *p_a = MyCAS::GetInstance(); // 创建一个对象，返回该类对象的指针
//    MyCAS *p_b = MyCAS::GetInstance();
//    p_a->func(); //该装载的数据装载
//    MyCAS::GetInstance()->func();

## 三：单例设计模式共享数据问题分析、解决
//        if (m_instance_ == nullptr) { // 双重锁定
//            std::unique_lock<std::mutex> my_mutex(resource_mutex); //自动加锁，只有第一次调用时才进来
//            if (m_instance_ == nullptr) {
//                m_instance_ = new MyCAS;
//                static CGarbageCollect cl;
//            }
//        }

## 四：std::call_once(); c++11,该函数第二个参数是函数名a();
// 功能：保证a()只能被调用一次
// 具备互斥量的能力，效率上更高效，消耗资源更少：
// 需要和标记std::once_flag结合使用
// 调用后改变std::once_flag的状态“已调用”

# 第八节
## 条件变量condition_variable、wait、notify_one、notify_all
std::condition_variable是一个类；  
```c++
std::mutex mymutex1;
std::unique_lock<std::mutex> sbguard1(mymutex1);
std::condition_variable condition;
condition.wait(sbguard1, [this] {if (!msgRecvQueue.empty())
                                    return true;
                                return false;
                                });
condition.wait(sbguard1);
```
wait()用来等待一个东西？  
wait()第二个参数返回false：解锁互斥量(unlock)，并组赛到本行；阻塞到其他某个线程调用notify_one()成员函数为止；  
wait()第二个参数返回true，那么wait()直接返回并继续执行；  
如果没有第二个参数，那么效果跟第二个参数lambda表达式返回false效果一样,wait()将解锁互斥量，并阻塞到本行，阻塞到其他某个线程调用notify_one()成员函数为止。  
其他线程用notify_one()将本线程wait()唤醒后，这个wait恢复后  
1、wait()不断尝试获取互斥量锁，如果获取不到那么流程就卡在wait()这里等待获取，如果获取到了，那么wait()就继续执行，获取到了锁  
2.1、如果wait有第二个参数就判断这个lambda表达式。  
a)如果表达式为false，那wait又对互斥量解锁，然后又休眠，等待再次被notify_one()唤醒  
b)如果lambda表达式为true，则wait返回，流程可以继续执行（此时互斥量已被锁住）。  
2.2、如果wait没有第二个参数，则wait返回，流程走下去。  
流程只要走到了wait()下面则互斥量一定被锁住了。 

## notify_all()
notify_one()：通知一个线程的wait()  
notify_all()：通知所有线程的wait()

# 第九节
## std::async、std::future创建后台任务并返回值
std::async是一个函数模板，用来启动一个异步任务，启动起来一个异步任务之后，它返回一个std::future对象，这个对象是个类模板。

**启动一个异步任务**:创建一个线程，开始执行线程的入口函数，他返回一个future对象，可以使用.get()获取结果

**get()**：会等待线程执行结果并返回结果，拿不到结果就一直等待；，感觉有点像join()。但是，它是可以获取结果的。

**wait()**: 用于等待线程返回，本身并不返回结果，这个效果和 std::thread 的join()更像。

**std::lunch::deferred**: （defer推迟，延期）表示线程入口函数的调用会被延迟，一直到std::future的wait()或者get()函数被调用时（由主线程调用）才会执行；如果wait()或者get()没有被调用，则不会执行。
实际上根本就没有创建新线程。std::launch::deferred意思时延迟调用，并没有创建新线程，是在主线程中调用的线程入口函数。

**std::launch::async**:在调用async函数的时候就开始创建新线程。

## std::packaged_task：打包任务，把任务包装起来。
类模板，它的模板参数是各种可调用对象，通过packaged_task把各种可调用对象包装起来，方便将来作为线程入口函数来调用。

## std::promise
我们能够在某个线程中给它赋值，然后我们可以在其他线程中，把这个值取出来

# 第十节
## std::future的其他成员函数

### std::future_status
std::future_status status = result.wait_for(std::chrono::seconds(几秒));
卡住当前流程，等待std::async()的异步任务运行一段时间，然后返回其状态std::future_status。  
如果std::async()的参数是std::launch::deferred（延迟执行），则不会卡住主流程。  
std::future_status是枚举类型，表示异步任务的执行状态。类型的取值有  
std::future_status::timeout   
std::future_status::ready  
std::future_status::deferred  

get()只能使用一次，比如如果
```c++
auto a = result.get();
cout << result.get() << endl; //error 报告异常
```
因为get()函数的设计是一个移动语义，相当于将result中的值移动到了a中，再次get就报告了异常。

## std::shared_future
std::future的 get() 成员函数是转移数据  
std::shared_future 的 get()成员函数是复制数据

## std::atomic原子操作
### 原子操作概念引出范例
互斥量：多线程编程中用于保护共享数据：先锁住，操作共享数据，解锁。

### 基本的std::atomic用法范例
* 原子操作：在多线程中不会被打断的程序执行片段。不需要用到互斥量加锁（无锁）技术的多线程并发编程方式。  
* 比互斥量的方式效率更高
* 互斥量的加锁一般是针对一个代码段，而原子操作针对的是一个变量
* 原子操作，一般都是指“不可分割的操作”；也就是说这种操作状态要么是完成的，要么是没完成的，不可能出现半完成状态。
* std::atomic来代表原子操作，是个类模板。其实std::atomic是用来封装某个类型的值的
* #include <atomic>
* 一般atomic原子操作，针对++，--，+=，-=，&=，|=，^=是支持的，其他操作不一定支持。

# 第十一节
## std::async深入理解
延迟调用参数 std::launch::deferred【延迟调用】，std::launch::async【强制创建一个线程】

std::async()我们一般不叫创建线程（他能够创建线程），我们一般叫它创建一个异步任务。

std::async和std::thread最明显的不同，就是 async 有时候并不创建新线程。

①如果用std::launch::deferred 来调用async？

延迟到调用 get() 或者 wait() 时执行，如果不调用就不会执行

②如果用std::launch::async来调用async？

强制这个异步任务在新线程上执行，这意味着，系统必须要创建出新线程来运行入口函数。

③如果同时用 std::launch::async | std::launch::deferred

这里这个 | 意味着async的行为可能是 std::launch::async 创建新线程立即执行， 也可能是 std::launch::deferred 没有创建新线程并且延迟到调用get()执行，由系统根据实际情况来决定采取哪种方案

④不带额外参数 std::async(mythread)，只给async 一个入口函数名，此时的系统给的默认值是 std::launch::async | std::launch::deferred 和 ③ 一样，有系统自行决定异步还是同步运行。

### 2.2 std::async和std::thread()区别：

std::thread()如果系统资源紧张可能出现创建线程失败的情况，如果创建线程失败那么程序就可能崩溃，而且不容易拿到函数返回值（不是拿不到）
std::async()创建异步任务。可能创建线程也可能不创建线程，并且容易拿到线程入口函数的返回值；

由于系统资源限制：
①如果用std::thread创建的线程太多，则可能创建失败，系统报告异常，崩溃。

②如果用std::async，一般就不会报异常，因为如果系统资源紧张，无法创建新线程的时候，async不加额外参数的调用方式就不会创建新线程。而是在后续调用get()请求结果时执行在这个调用get()的线程上。

如果你强制async一定要创建新线程就要使用 std::launch::async 标记。承受的代价是，系统资源紧张时可能崩溃。

③根据经验，一个程序中线程数量 不宜超过100~200 。

## 2.3 async不确定性问题的解决
不加额外参数的async调用时让系统自行决定，是否创建新线程。

std::future<int> result = std::async(mythread);
问题焦点在于这个写法，任务到底有没有被推迟执行。

通过wait_for返回状态来判断：
```c++
std::future_status status = result.wait_for(std::chrono::seconds(6));
//std::future_status status = result.wait_for(6s);
if (status == std::future_status::timeout) {
//超时：表示线程还没有执行完
cout << "超时了，线程还没有执行完" << endl;
}
else if (status == std::future_status::ready) {
//表示线程成功放回
cout << "线程执行成功，返回" << endl;
cout << result.get() << endl;
}
else if (status == std::future_status::deferred) {
cout << "线程延迟执行" << endl;
cout << result.get() << endl;
}
```

# 第十二节 windows临界区、其他各种mutex互斥量

## 一和二、windows临界区
Windows临界区，同一个线程是可以重复进入的，但是进入的次数与离开的次数必须相等。
C++互斥量则不允许同一个线程重复加锁。

windows临界区是在windows编程中的内容，了解一下即可，效果几乎可以等同于c++11的mutex
包含#include <windows.h>
windows中的临界区同mutex一样，可以保护一个代码段。但windows的临界区可以进入多次，离开多次，但是进入的次数与离开的次数必须相等，不会引起程序报异常出错
三、自动析构技术
C++：lock_guard防止忘了释放信号量，自动释放
windows：可以写个类自动释放临界区：

class CWinLock {
public:
CWinLock(CRITICAL_SECTION *pCritmp)
{
my_winsec =pCritmp;
EnterCriticalSection(my_winsec);
}
~CWinLock()
{
LeaveCriticalSection(my_winsec)
};
private:
CRITICAL_SECTION *my_winsec;
};
1
2
3
4
5
6
7
8
9
10
11
12
13
14
上述这种类RAII类（Resource Acquisition is initialization），即资源获取及初始化。容器，智能指针属于这种类。

四、递归独占互斥量 std::recursive_mutex
std::mutex 独占式互斥量

std::recursive_mutex：允许在同一个线程中同一个互斥量多次被 lock() ，（但是递归加锁的次数是有限制的，太多可能会报异常），效率要比mutex低。

如果你真的用了 recursive_mutex 要考虑代码是否有优化空间，如果能调用一次 lock()就不要调用多次。

五、带超时的互斥量 std::timed_mutex 和 std::recursive_timed_mutex

5.1 std::timed_mutex：是待超时的独占互斥量

try_lock_for()：
等待一段时间，如果拿到了锁，或者超时了未拿到锁，就继续执行（有选择执行）如下：

std::chrono::milliseconds timeout(100);
if (my_mymutex.try_lock_for(timeout)){
//......拿到锁返回ture
}
else{
std::chrono::milliseconds sleeptime(100);
std::this_thread::sleep_for(sleeptime);
}

try_lock_until()：
参数是一个未来的时间点，在这个未来的时间没到的时间内，如果拿到了锁头，流程就走下来，如果时间到了没拿到锁，流程也可以走下来。

std::chrono::milliseconds timeout(100);
if (my_mymutex.try_lock_until(chrono::steady_clock::now() + timeout)){
//......拿到锁返回ture
}
else{
std::chrono::milliseconds sleeptime(100);
std::this_thread::sleep_for(sleeptime);
}

两者的区别就是一个参数是时间段，一个参数是时间点

5.2 std::recursive_timed_mutex：是待超时的递归独占互斥量

# 第十三节
## 一、补充一些知识点
1.1 虚假唤醒：
notify_one或者notify_all唤醒wait()后，实际有些线程可能不满足唤醒的条件，就会造成虚假唤醒，可以在wait中再次进行判断解决虚假唤醒。
解决：wait中要有第二个参数（lambda），并且这个lambda中要正确判断所处理的公共数据是否存在。

2.2 atomic：
std::atomic<int> atm = 0;
cout << atm << endl;

这里只有读取atm是原子操作，但是整个这一行代码 cout << atm << endl; 并不是原子操作，导致最终显示在屏幕上的值是一个“曾经值”。

std::atomic<int> atm = 0;

auto atm2 = atm; //不可以
这种拷贝初始化不可以，会报错。

atomic<int> atm2(atm.load());

load()：以原子方式读atomic对象的值。

atm2.store(12);

原子操作实质上是：不允许在进行原子对象操作时进行CPU的上下文切换。
## 二、浅谈线程池：
场景设想：服务器程序， 每来一个客户端，就创建一个新线程为这个客户提供服务。

问题：

1、2万个玩家，不可能给每个玩家创建一个新线程，此程序写法在这种场景下不通。

2、程序稳定性问题：编写代码中，“时不时地突然”创建一个线程，这种写法，一般情况下不会出错，但是不稳定的；

线程池：把一堆线程弄到一起，统一管理。这种统一管理调度，循环利用的方式，就叫做线程池。

实现方式：程序启动时，一次性创建好一定数量的线程。这种方式让人更放心，觉得程序代码更稳定。

## 三、线程创建数量谈：

1、线程创建的数量极限的问题

一般来讲，2000个线程基本就是极限；再创建就会崩溃。

2、线程创建数量建议

a、采用某些计数开发程序提供的建议，遵照建议和指示来确保程序高效执行。

b、创建多线程完成业务；考虑可能被阻塞的线程数量，创建多余最大被阻塞线程数量的线程，如100个线程被阻塞再充值业务，开110个线程就是很合适的

c、线程创建数量尽量不要超过500个，尽量控制在200个之内；
